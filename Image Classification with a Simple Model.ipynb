{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building your own model with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.backend import clear_session\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, ReLU, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = ''\n",
    "train_folders_path = os.path.join(base_path,'train')\n",
    "validation_folders_path = ''\n",
    "test_folders_path = os.path.join(base_path,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classlabels = os.listdir(train_folders_path)\n",
    "print(classlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dimensions\n",
    "img_width, img_height = 224, 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Step 1 - Convolutional layers\n",
    "## Adding the first convolutional layer\n",
    "model.add(Conv2D(32, (3, 3),padding='same', input_shape = (img_width, img_height, 3)))\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "model.add(Conv2D(64, (3, 3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a third convolutional layer\n",
    "model.add(Conv2D(128, (3, 3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#Adding a fourth convolutional layer\n",
    "model.add(Conv2D(256, (3, 3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#Adding a fifth convolutional layer\n",
    "model.add(Conv2D(512, (3, 3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#Adding a sixth convolutional layer\n",
    "model.add(Conv2D(1024, (3, 3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# and so on with the number of Conv2D filters GENERALLY increasing by powers of 2\n",
    "\n",
    "# Step 2 - Global Average Pooling\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Step 3 - Full connection\n",
    "model.add(Dense(units = 1024))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ReLU())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units = len(classlabels), activation = 'softmax'))\n",
    "\n",
    "# Compiling the CNN\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   rotation_range=30,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   validation_split=0.2)\n",
    "\n",
    "print('Making training data generator...')\n",
    "training_set = datagen.flow_from_directory(train_folders_path,\n",
    "                                           target_size = (img_width, img_height),\n",
    "                                           batch_size = 32,\n",
    "                                           class_mode = 'categorical',\n",
    "                                           subset='training')\n",
    "\n",
    "print('Making validation data generator...')\n",
    "cv_set = datagen.flow_from_directory(train_folders_path,\n",
    "                                       target_size = (img_width, img_height),\n",
    "                                       batch_size = 32,\n",
    "                                       class_mode = 'categorical',\n",
    "                                       subset='validation',\n",
    "                                       shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ES = EarlyStopping(monitor='val_accuracy', patience=20)\n",
    "MC = ModelCheckpoint(\n",
    "    filepath=(os.path.join(base_path, 'CNN Model')),\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1)\n",
    "LR = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=5, min_lr = 1e-8, mode='max',verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(training_set,\n",
    "                         steps_per_epoch = (training_set.n // 32)+1,\n",
    "                         epochs = 100,\n",
    "                         validation_data = cv_set,\n",
    "                         validation_steps = (cv_set.n//32)+1,\n",
    "                         callbacks=[ES1,MC1,LR1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After error analysis, if we see that there is overfitting, we can add in L2 regularizers in the hidden layers with the following format:\n",
    "\n",
    "For example, the 2nd Conv Layer: \n",
    "<br>\n",
    "model.add(Conv2D(64, (3, 3),__kernel_regularizer=l2(0.01)__, padding='same'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other possible solutions can include:<br>\n",
    "Increase the Dropout(0.1) -> Dropout(0.5)<br>\n",
    "Decrease the number of hidden layers\n",
    "\n",
    "\n",
    "In the case of a vanishing gradient issue:\n",
    "We can utilise __LeakyReLU__ instead of __ReLU__ activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
